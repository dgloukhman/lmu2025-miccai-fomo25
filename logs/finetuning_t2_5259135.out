Running test script on host mcml-hgx-a100-004 custom finetuning

Error: Oh My Zsh can't be loaded from: slurm_script. You need to run zsh instead.
Here's the process tree:

   PPID     PID COMMAND
      1 3377460 slurmstepd: [5259135.batch]
3377460 3377464  \_ /bin/bash /var/lib/slurm-llnl/slurmd/job5259135/slurm_script

WARNING:root:Reusing already computed split file which was split using the simple_train_val_split method and parameter 0.2.
WARNING:root:Reusing already computed split file which was split using the simple_train_val_split method and parameter 0.2.
WARNING:root:Reusing already computed split file which was split using the simple_train_val_split method and parameter 0.2.
[rank: 1] Seed set to 731195956
WARNING:root:Reusing already computed split file which was split using the simple_train_val_split method and parameter 0.2.
[rank: 2] Seed set to 731195956
[rank: 0] Seed set to 731195956
[rank: 3] Seed set to 731195956
INFO:root:Starting model training 
log file:            /dss/dsshome1/04/ra58seq2/unet/finetuned/t2/Task002_FOMO2/unet_xl/version_34/training_log.txt 

INFO:root:Using 8 workers
INFO:root:Using dataset class: <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTrainDataset'> for train/val and <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTestDataset'> for inference
INFO:root:Using 8 workers
INFO:root:Using dataset class: <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTrainDataset'> for train/val and <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTestDataset'> for inference
INFO:root:Using 8 workers
INFO:root:Using dataset class: <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTrainDataset'> for train/val and <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTestDataset'> for inference
INFO:root:Using 8 workers
INFO:root:Using dataset class: <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTrainDataset'> for train/val and <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTestDataset'> for inference
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
WARNING:root:Succesfully transferred weights for 63/82 layers
WARNING:root:Rejected the following keys:
Not in old dict: [].
Wrong shape: [].
Post check not succesful: ['model.encoder.in_conv.conv1.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.bias', 'model.decoder.decoder_conv1.conv2.norm.weight', 'model.decoder.decoder_conv1.conv2.norm.bias', 'model.decoder.decoder_conv2.conv2.conv.weight', 'model.decoder.decoder_conv2.conv2.conv.bias', 'model.decoder.decoder_conv2.conv2.norm.weight', 'model.decoder.decoder_conv2.conv2.norm.bias', 'model.decoder.decoder_conv3.conv2.conv.weight', 'model.decoder.decoder_conv3.conv2.conv.bias', 'model.decoder.decoder_conv3.conv2.norm.weight', 'model.decoder.decoder_conv3.conv2.norm.bias', 'model.decoder.decoder_conv4.conv2.conv.weight', 'model.decoder.decoder_conv4.conv2.conv.bias', 'model.decoder.decoder_conv4.conv2.norm.weight', 'model.decoder.decoder_conv4.conv2.norm.bias', 'model.decoder.out_conv.weight', 'model.decoder.out_conv.bias'].
WARNING:root:Succesfully transferred weights for 63/82 layers
WARNING:root:Rejected the following keys:
Not in old dict: [].
Wrong shape: [].
Post check not succesful: ['model.encoder.in_conv.conv1.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.bias', 'model.decoder.decoder_conv1.conv2.norm.weight', 'model.decoder.decoder_conv1.conv2.norm.bias', 'model.decoder.decoder_conv2.conv2.conv.weight', 'model.decoder.decoder_conv2.conv2.conv.bias', 'model.decoder.decoder_conv2.conv2.norm.weight', 'model.decoder.decoder_conv2.conv2.norm.bias', 'model.decoder.decoder_conv3.conv2.conv.weight', 'model.decoder.decoder_conv3.conv2.conv.bias', 'model.decoder.decoder_conv3.conv2.norm.weight', 'model.decoder.decoder_conv3.conv2.norm.bias', 'model.decoder.decoder_conv4.conv2.conv.weight', 'model.decoder.decoder_conv4.conv2.conv.bias', 'model.decoder.decoder_conv4.conv2.norm.weight', 'model.decoder.decoder_conv4.conv2.norm.bias', 'model.decoder.out_conv.weight', 'model.decoder.out_conv.bias'].
/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:190: .fit(ckpt_path="last") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.
WARNING:root:Succesfully transferred weights for 63/82 layers
WARNING:root:Rejected the following keys:
Not in old dict: [].
Wrong shape: [].
Post check not succesful: ['model.encoder.in_conv.conv1.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.bias', 'model.decoder.decoder_conv1.conv2.norm.weight', 'model.decoder.decoder_conv1.conv2.norm.bias', 'model.decoder.decoder_conv2.conv2.conv.weight', 'model.decoder.decoder_conv2.conv2.conv.bias', 'model.decoder.decoder_conv2.conv2.norm.weight', 'model.decoder.decoder_conv2.conv2.norm.bias', 'model.decoder.decoder_conv3.conv2.conv.weight', 'model.decoder.decoder_conv3.conv2.conv.bias', 'model.decoder.decoder_conv3.conv2.norm.weight', 'model.decoder.decoder_conv3.conv2.norm.bias', 'model.decoder.decoder_conv4.conv2.conv.weight', 'model.decoder.decoder_conv4.conv2.conv.bias', 'model.decoder.decoder_conv4.conv2.norm.weight', 'model.decoder.decoder_conv4.conv2.norm.bias', 'model.decoder.out_conv.weight', 'model.decoder.out_conv.bias'].
WARNING:root:Succesfully transferred weights for 63/82 layers
WARNING:root:Rejected the following keys:
Not in old dict: [].
Wrong shape: [].
Post check not succesful: ['model.encoder.in_conv.conv1.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.weight', 'model.decoder.decoder_conv1.conv2.conv.bias', 'model.decoder.decoder_conv1.conv2.norm.weight', 'model.decoder.decoder_conv1.conv2.norm.bias', 'model.decoder.decoder_conv2.conv2.conv.weight', 'model.decoder.decoder_conv2.conv2.conv.bias', 'model.decoder.decoder_conv2.conv2.norm.weight', 'model.decoder.decoder_conv2.conv2.norm.bias', 'model.decoder.decoder_conv3.conv2.conv.weight', 'model.decoder.decoder_conv3.conv2.conv.bias', 'model.decoder.decoder_conv3.conv2.norm.weight', 'model.decoder.decoder_conv3.conv2.norm.bias', 'model.decoder.decoder_conv4.conv2.conv.weight', 'model.decoder.decoder_conv4.conv2.conv.bias', 'model.decoder.decoder_conv4.conv2.norm.weight', 'model.decoder.decoder_conv4.conv2.norm.bias', 'model.decoder.out_conv.weight', 'model.decoder.out_conv.bias'].
INFO:root:Setting up data for stage: fit
INFO:root:Validating on samples: ['/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1050', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2765', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3814', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3279', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2000', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10822', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5285', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3669', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_302', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3899', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4170', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3570', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7148', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7933', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4025', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_15', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2020', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1215', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6798', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10518', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5886', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9463', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5410', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_904', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4744', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10393', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5595', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3194', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5245', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1380', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_17', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_322', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9647', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5080', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7438', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4315', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8368', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_22', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2640', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7108', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8097', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6693', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9107', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9153', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10683', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3115', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11138', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_20', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4764', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10103', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5674', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2165', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9252', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7082', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_236', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10512', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1109', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7293', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4454', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9318', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7128', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6818', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2659', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8203', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3589', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1235', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9582', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5265', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5404', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8698', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11013', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2475']
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:root:Setting up data for stage: fit
INFO:root:Validating on samples: ['/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1050', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2765', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3814', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3279', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2000', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10822', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5285', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3669', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_302', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3899', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4170', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3570', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7148', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7933', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4025', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_15', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2020', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1215', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6798', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10518', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5886', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9463', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5410', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_904', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4744', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10393', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5595', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3194', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5245', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1380', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_17', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_322', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9647', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5080', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7438', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4315', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8368', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_22', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2640', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7108', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8097', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6693', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9107', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9153', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10683', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3115', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11138', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_20', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4764', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10103', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5674', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2165', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9252', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7082', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_236', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10512', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1109', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7293', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4454', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9318', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7128', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6818', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2659', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8203', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3589', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1235', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9582', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5265', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5404', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8698', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11013', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2475']
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:root:Setting up data for stage: fit
INFO:root:Validating on samples: ['/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1050', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2765', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3814', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3279', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2000', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10822', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5285', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3669', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_302', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3899', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4170', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3570', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7148', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7933', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4025', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_15', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2020', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1215', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6798', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10518', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5886', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9463', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5410', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_904', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4744', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10393', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5595', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3194', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5245', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1380', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_17', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_322', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9647', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5080', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7438', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4315', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8368', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_22', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2640', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7108', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8097', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6693', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9107', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9153', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10683', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3115', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11138', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_20', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4764', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10103', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5674', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2165', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9252', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7082', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_236', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10512', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1109', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7293', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4454', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9318', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7128', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6818', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2659', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8203', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3589', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1235', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9582', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5265', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5404', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8698', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11013', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2475']
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
wandb: Currently logged in as: daniel-gloukhman (daniel-gloukhman-ludwig-maximilianuniversity-of-munich) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin

  | Name          | Type             | Params | Mode 
-----------------------------------------------------------
0 | train_metrics | MetricCollection | 0      | train
1 | val_metrics   | MetricCollection | 0      | train
2 | model         | UNet             | 90.3 M | train
3 | loss_fn_train | DiceCE           | 0      | train
4 | loss_fn_val   | DiceCE           | 0      | train
-----------------------------------------------------------
90.3 M    Trainable params
0         Non-trainable params
90.3 M    Total params
361.232   Total estimated model params size (MB)
105       Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Using num_workers: 8, num_devices: 1
Task type: segmentation
ARGS: Namespace(data_dir='/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed', save_dir='/dss/dsshome1/04/ra58seq2/unet/finetuned/t2', pretrained_weights_path='/dss/dsshome1/04/ra58seq2/unet/models/FOMO60k/unet_xl_lw_dec/versions/version_0/epoch=99.ckpt', model_name='unet_xl', precision='bf16-mixed', patch_size=96, learning_rate=0.0001, compile=False, compile_mode=None, num_devices=1, num_workers=8, fast_dev_run=False, new_version=True, augmentation_preset='clone_all', epochs=500, batch_size=4, train_batches_per_epoch=100, taskid=2, split_method='simple_train_val_split', split_param=0.2, split_idx=0, experiment='finetuning with larger artificial dataset')
{'clone_minigioma_p_per_sample': 1.0, 'normalize': False}
Composing Transforms



Compose(
    CollectMetadata( data_key = 'image', label_key = 'label' )
    AddBatchDimension( data_key = 'image', label_key = 'label' )
    Spatial( data_key = 'image', label_key = 'label', skip_label = False, order = 3, do_crop = True, cval = 'min', patch_size = (96, 96, 96), random_crop = False, clip_to_input_range = False, p_deform_per_sample = 0.33, deform_sigma = (20, 30), deform_alpha = (200, 600), p_rot_per_sample = 0.2, p_rot_per_axis = 0.66, x_rot_in_degrees = (-30.0, 30.0), y_rot_in_degrees = (-30.0, 30.0), z_rot_in_degrees = (-30.0, 30.0), p_scale_per_sample = 0.2, scale_factor = (0.9, 1.1) )
    AdditiveNoise( data_key = 'image', p_per_sample = 0.2, mean = (0.0, 0.0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    Blur( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, sigma = (0.0, 1.0), clip_to_input_range = False )
    MultiplicativeNoise( data_key = 'image', p_per_sample = 0.2, mean = (0, 0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    MotionGhosting( data_key = 'image', p_per_sample = 0.2, alpha = (0.85, 0.95), num_reps = (2, 11), axes = (0, 3), clip_to_input_range = False )
    GibbsRinging( data_key = 'image', p_per_sample = 0.2, cut_freq = (96, 129), axes = (0, 3), clip_to_input_range = False )
    SimulateLowres( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, p_per_axis = 0.33, zoom_range = (0.5, 1.0), clip_to_input_range = False )
    BiasField( data_key = 'image', p_per_sample = 0.33, clip_to_input_range = False )
    Gamma( data_key = 'image', p_per_sample = 0.2, gamma_range = (0.5, 2.0), p_invert_image = 0.05, per_channel = True, clip_to_input_range = False )
    Mirror( data_key = 'image', label_key = 'label', p_per_sample = 0.0, p_mirror_per_axis = 0.33, axes = (0, 1, 2), skip_label = False )
    Normalize( normalize = False, data_key = 'image', metadata_key = 'metadata', scheme = 'volume_wise_znorm' )
    Skeleton( label_key = 'label', skeleton = False, do_tube = False )
    ConvertLabelsToRegions( convert_labels_to_regions = False, label_key = 'label' )
    CopyImageToLabel( copy = False, data_key = 'image', label_key = 'label' )
    DownsampleSegForDS( deep_supervision = False, label_key = 'label', factors = (1, 0.5, 0.25, 0.125, 0.0625) )
    Masking( mask = False, data_key = 'image', ratio = 0.5, token_size = 0.05, pixel_value = 'min' )
    RemoveBatchDimension( data_key = 'image', label_key = 'label' )
    <augmentations.clone_segmentation.CloneMinigioma object at 0x7fd4c5e4b3a0>
)



Train dataset:  ['FOMO2_sub_1090', 'FOMO2_sub_11033', 'FOMO2_sub_6983', 'FOMO2_sub_7', 'FOMO2_sub_4335', 'FOMO2_sub_10373', 'FOMO2_sub_6673', 'FOMO2_sub_1374', 'FOMO2_sub_1994', 'FOMO2_sub_4150', 'FOMO2_sub_5694', 'FOMO2_sub_1479', 'FOMO2_sub_5700', 'FOMO2_sub_1044', 'FOMO2_sub_8012', 'FOMO2_sub_7787', 'FOMO2_sub_8553', 'FOMO2_sub_8038', 'FOMO2_sub_3979', 'FOMO2_sub_6197', 'FOMO2_sub_10828', 'FOMO2_sub_5906', 'FOMO2_sub_5760', 'FOMO2_sub_8843', 'FOMO2_sub_2145', 'FOMO2_sub_6772', 'FOMO2_sub_2185', 'FOMO2_sub_9298', 'FOMO2_sub_6963', 'FOMO2_sub_1855', 'FOMO2_sub_1334', 'FOMO2_sub_1400', 'FOMO2_sub_3385', 'FOMO2_sub_2785', 'FOMO2_sub_8658', 'FOMO2_sub_1360', 'FOMO2_sub_2910', 'FOMO2_sub_10577', 'FOMO2_sub_6462', 'FOMO2_sub_3260', 'FOMO2_sub_7102', 'FOMO2_sub_18', 'FOMO2_sub_8348', 'FOMO2_sub_633', 'FOMO2_sub_4665', 'FOMO2_sub_23', 'FOMO2_sub_1974', 'FOMO2_sub_10208', 'FOMO2_sub_8217', 'FOMO2_sub_8817', 'FOMO2_sub_8823', 'FOMO2_sub_5866', 'FOMO2_sub_3359', 'FOMO2_sub_10057', 'FOMO2_sub_7273', 'FOMO2_sub_3880', 'FOMO2_sub_1670', 'FOMO2_sub_9727', 'FOMO2_sub_2', 'FOMO2_sub_5555', 'FOMO2_sub_4190', 'FOMO2_sub_7583', 'FOMO2_sub_7623', 'FOMO2_sub_6488', 'FOMO2_sub_3530', 'FOMO2_sub_8487', 'FOMO2_sub_924', 'FOMO2_sub_3834', 'FOMO2_sub_7003', 'FOMO2_sub_1954', 'FOMO2_sub_3524', 'FOMO2_sub_10267', 'FOMO2_sub_6177', 'FOMO2_sub_262', 'FOMO2_sub_4955', 'FOMO2_sub_7702', 'FOMO2_sub_10228', 'FOMO2_sub_9957', 'FOMO2_sub_2310', 'FOMO2_sub_6547', 'FOMO2_sub_1809', 'FOMO2_sub_713', 'FOMO2_sub_4770', 'FOMO2_sub_3695', 'FOMO2_sub_7227', 'FOMO2_sub_5054', 'FOMO2_sub_878', 'FOMO2_sub_898', 'FOMO2_sub_1729', 'FOMO2_sub_8678', 'FOMO2_sub_8058', 'FOMO2_sub_6917', 'FOMO2_sub_6653', 'FOMO2_sub_10347', 'FOMO2_sub_11178', 'FOMO2_sub_4519', 'FOMO2_sub_4124', 'FOMO2_sub_91', 'FOMO2_sub_3095', 'FOMO2_sub_21', 'FOMO2_sub_8388', 'FOMO2_sub_1189', 'FOMO2_sub_10', 'FOMO2_sub_5390', 'FOMO2_sub_256', 'FOMO2_sub_6217', 'FOMO2_sub_4005', 'FOMO2_sub_16', 'FOMO2_sub_2739', 'FOMO2_sub_9008', 'FOMO2_sub_9', 'FOMO2_sub_8863', 'FOMO2_sub_5430', 'FOMO2_sub_9278', 'FOMO2_sub_7313', 'FOMO2_sub_4209', 'FOMO2_sub_10182', 'FOMO2_sub_759', 'FOMO2_sub_6382', 'FOMO2_sub_2574', 'FOMO2_sub_4480', 'FOMO2_sub_5720', 'FOMO2_sub_4784', 'FOMO2_sub_9133', 'FOMO2_sub_8988', 'FOMO2_sub_1690', 'FOMO2_sub_10558', 'FOMO2_sub_3840', 'FOMO2_sub_8243', 'FOMO2_sub_14', 'FOMO2_sub_468', 'FOMO2_sub_4975', 'FOMO2_sub_4909', 'FOMO2_sub_5', 'FOMO2_sub_2264', 'FOMO2_sub_607', 'FOMO2_sub_7477', 'FOMO2_sub_1070', 'FOMO2_sub_593', 'FOMO2_sub_7167', 'FOMO2_sub_5740', 'FOMO2_sub_779', 'FOMO2_sub_8942', 'FOMO2_sub_8717', 'FOMO2_sub_428', 'FOMO2_sub_10077', 'FOMO2_sub_10202', 'FOMO2_sub_2930', 'FOMO2_sub_10802', 'FOMO2_sub_4949', 'FOMO2_sub_6151', 'FOMO2_sub_7867', 'FOMO2_sub_4500', 'FOMO2_sub_6316', 'FOMO2_sub_1255', 'FOMO2_sub_6857', 'FOMO2_sub_1354', 'FOMO2_sub_2349', 'FOMO2_sub_7458', 'FOMO2_sub_9892', 'FOMO2_sub_1644', 'FOMO2_sub_157', 'FOMO2_sub_3049', 'FOMO2_sub_6', 'FOMO2_sub_8078', 'FOMO2_sub_5449', 'FOMO2_sub_9918', 'FOMO2_sub_6296', 'FOMO2_sub_9337', 'FOMO2_sub_8', 'FOMO2_sub_10248', 'FOMO2_sub_6508', 'FOMO2_sub_9027', 'FOMO2_sub_8223', 'FOMO2_sub_10037', 'FOMO2_sub_2039', 'FOMO2_sub_5219', 'FOMO2_sub_10887', 'FOMO2_sub_448', 'FOMO2_sub_9938', 'FOMO2_sub_1980', 'FOMO2_sub_8632', 'FOMO2_sub_2455', 'FOMO2_sub_9147', 'FOMO2_sub_5139', 'FOMO2_sub_5100', 'FOMO2_sub_8322', 'FOMO2_sub_8968', 'FOMO2_sub_2950', 'FOMO2_sub_1789', 'FOMO2_sub_5575', 'FOMO2_sub_9773', 'FOMO2_sub_2884', 'FOMO2_sub_7247', 'FOMO2_sub_5120', 'FOMO2_sub_7748', 'FOMO2_sub_9753', 'FOMO2_sub_7728', 'FOMO2_sub_10063', 'FOMO2_sub_6838', 'FOMO2_sub_3425', 'FOMO2_sub_2805', 'FOMO2_sub_7418', 'FOMO2_sub_2495', 'FOMO2_sub_10993', 'FOMO2_sub_9793', 'FOMO2_sub_8177', 'FOMO2_sub_2290', 'FOMO2_sub_10703', 'FOMO2_sub_9173', 'FOMO2_sub_10657', 'FOMO2_sub_2330', 'FOMO2_sub_739', 'FOMO2_sub_5529', 'FOMO2_sub_10222', 'FOMO2_sub_9483', 'FOMO2_sub_4625', 'FOMO2_sub_1829', 'FOMO2_sub_8533', 'FOMO2_sub_9457', 'FOMO2_sub_13', 'FOMO2_sub_4810', 'FOMO2_sub_6937', 'FOMO2_sub_2119', 'FOMO2_sub_5985', 'FOMO2_sub_3715', 'FOMO2_sub_3504', 'FOMO2_sub_1710', 'FOMO2_sub_1525', 'FOMO2_sub_7893', 'FOMO2_sub_2969', 'FOMO2_sub_11132', 'FOMO2_sub_9628', 'FOMO2_sub_4619', 'FOMO2_sub_9272', 'FOMO2_sub_6362', 'FOMO2_sub_10987', 'FOMO2_sub_4935', 'FOMO2_sub_8797', 'FOMO2_sub_12', 'FOMO2_sub_3860', 'FOMO2_sub_9898', 'FOMO2_sub_137', 'FOMO2_sub_117', 'FOMO2_sub_7603', 'FOMO2_sub_7907', 'FOMO2_sub_2924', 'FOMO2_sub_9562', 'FOMO2_sub_2600', 'FOMO2_sub_1565', 'FOMO2_sub_1419', 'FOMO2_sub_10723', 'FOMO2_sub_10538', 'FOMO2_sub_3550', 'FOMO2_sub_5364', 'FOMO2_sub_4829', 'FOMO2_sub_613', 'FOMO2_sub_858', 'FOMO2_sub_3075', 'FOMO2_sub_6342', 'FOMO2_sub_6045', 'FOMO2_sub_1545', 'FOMO2_sub_9608', 'FOMO2_sub_4045', 'FOMO2_sub_4599', 'FOMO2_sub_4790', 'FOMO2_sub_3220', 'FOMO2_sub_547', 'FOMO2_sub_11158', 'FOMO2_sub_11112', 'FOMO2_sub_6051', 'FOMO2_sub_4645', 'FOMO2_sub_9443', 'FOMO2_sub_1', 'FOMO2_sub_2759', 'FOMO2_sub_3', 'FOMO2_sub_8407', 'FOMO2_sub_4434', 'FOMO2_sub_19', 'FOMO2_sub_4144', 'FOMO2_sub_3240', 'FOMO2_sub_282', 'FOMO2_sub_6031', 'FOMO2_sub_944', 'FOMO2_sub_4460', 'FOMO2_sub_4', 'FOMO2_sub_6005', 'FOMO2_sub_10848', 'FOMO2_sub_5840', 'FOMO2_sub_4355']
Val dataset:  ['FOMO2_sub_1050', 'FOMO2_sub_2765', 'FOMO2_sub_11', 'FOMO2_sub_3814', 'FOMO2_sub_3279', 'FOMO2_sub_2000', 'FOMO2_sub_10822', 'FOMO2_sub_5285', 'FOMO2_sub_3669', 'FOMO2_sub_302', 'FOMO2_sub_3899', 'FOMO2_sub_4170', 'FOMO2_sub_3570', 'FOMO2_sub_7148', 'FOMO2_sub_7933', 'FOMO2_sub_4025', 'FOMO2_sub_15', 'FOMO2_sub_2020', 'FOMO2_sub_1215', 'FOMO2_sub_6798', 'FOMO2_sub_10518', 'FOMO2_sub_5886', 'FOMO2_sub_9463', 'FOMO2_sub_5410', 'FOMO2_sub_904', 'FOMO2_sub_4744', 'FOMO2_sub_10393', 'FOMO2_sub_5595', 'FOMO2_sub_3194', 'FOMO2_sub_5245', 'FOMO2_sub_1380', 'FOMO2_sub_17', 'FOMO2_sub_322', 'FOMO2_sub_9647', 'FOMO2_sub_5080', 'FOMO2_sub_7438', 'FOMO2_sub_4315', 'FOMO2_sub_8368', 'FOMO2_sub_22', 'FOMO2_sub_2640', 'FOMO2_sub_7108', 'FOMO2_sub_8097', 'FOMO2_sub_6693', 'FOMO2_sub_9107', 'FOMO2_sub_9153', 'FOMO2_sub_10683', 'FOMO2_sub_3115', 'FOMO2_sub_11138', 'FOMO2_sub_20', 'FOMO2_sub_4764', 'FOMO2_sub_10103', 'FOMO2_sub_5674', 'FOMO2_sub_2165', 'FOMO2_sub_9252', 'FOMO2_sub_7082', 'FOMO2_sub_236', 'FOMO2_sub_10512', 'FOMO2_sub_1109', 'FOMO2_sub_7293', 'FOMO2_sub_4454', 'FOMO2_sub_9318', 'FOMO2_sub_7128', 'FOMO2_sub_6818', 'FOMO2_sub_2659', 'FOMO2_sub_8203', 'FOMO2_sub_3589', 'FOMO2_sub_1235', 'FOMO2_sub_9582', 'FOMO2_sub_5265', 'FOMO2_sub_5404', 'FOMO2_sub_8698', 'FOMO2_sub_11013', 'FOMO2_sub_2475']
Run type:  finetune
Starting training with 50000 max iterations over 500 epochs with train dataset of size 290 datapoints and val dataset of size 73 and effective batch size of 4
Loading Model: 3D unet_xl
Found model class:  <function unet_xl at 0x7fd4c703e710>
MODALITIES 3
Transferring weights for finetuning
Checkpoint path: None
Loading from PyTorch Lightning checkpoint

  | Name          | Type             | Params | Mode 
-----------------------------------------------------------
0 | train_metrics | MetricCollection | 0      | train
1 | val_metrics   | MetricCollection | 0      | train
2 | model         | UNet             | 90.3 M | train
3 | loss_fn_train | DiceCE           | 0      | train
4 | loss_fn_val   | DiceCE           | 0      | train
-----------------------------------------------------------
90.3 M    Trainable params
0         Non-trainable params
90.3 M    Total params
361.232   Total estimated model params size (MB)
105       Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Using num_workers: 8, num_devices: 1
Task type: segmentation
ARGS: Namespace(data_dir='/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed', save_dir='/dss/dsshome1/04/ra58seq2/unet/finetuned/t2', pretrained_weights_path='/dss/dsshome1/04/ra58seq2/unet/models/FOMO60k/unet_xl_lw_dec/versions/version_0/epoch=99.ckpt', model_name='unet_xl', precision='bf16-mixed', patch_size=96, learning_rate=0.0001, compile=False, compile_mode=None, num_devices=1, num_workers=8, fast_dev_run=False, new_version=True, augmentation_preset='clone_all', epochs=500, batch_size=4, train_batches_per_epoch=100, taskid=2, split_method='simple_train_val_split', split_param=0.2, split_idx=0, experiment='finetuning with larger artificial dataset')
{'clone_minigioma_p_per_sample': 1.0, 'normalize': False}
Composing Transforms



Compose(
    CollectMetadata( data_key = 'image', label_key = 'label' )
    AddBatchDimension( data_key = 'image', label_key = 'label' )
    Spatial( data_key = 'image', label_key = 'label', skip_label = False, order = 3, do_crop = True, cval = 'min', patch_size = (96, 96, 96), random_crop = False, clip_to_input_range = False, p_deform_per_sample = 0.33, deform_sigma = (20, 30), deform_alpha = (200, 600), p_rot_per_sample = 0.2, p_rot_per_axis = 0.66, x_rot_in_degrees = (-30.0, 30.0), y_rot_in_degrees = (-30.0, 30.0), z_rot_in_degrees = (-30.0, 30.0), p_scale_per_sample = 0.2, scale_factor = (0.9, 1.1) )
    AdditiveNoise( data_key = 'image', p_per_sample = 0.2, mean = (0.0, 0.0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    Blur( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, sigma = (0.0, 1.0), clip_to_input_range = False )
    MultiplicativeNoise( data_key = 'image', p_per_sample = 0.2, mean = (0, 0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    MotionGhosting( data_key = 'image', p_per_sample = 0.2, alpha = (0.85, 0.95), num_reps = (2, 11), axes = (0, 3), clip_to_input_range = False )
    GibbsRinging( data_key = 'image', p_per_sample = 0.2, cut_freq = (96, 129), axes = (0, 3), clip_to_input_range = False )
    SimulateLowres( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, p_per_axis = 0.33, zoom_range = (0.5, 1.0), clip_to_input_range = False )
    BiasField( data_key = 'image', p_per_sample = 0.33, clip_to_input_range = False )
    Gamma( data_key = 'image', p_per_sample = 0.2, gamma_range = (0.5, 2.0), p_invert_image = 0.05, per_channel = True, clip_to_input_range = False )
    Mirror( data_key = 'image', label_key = 'label', p_per_sample = 0.0, p_mirror_per_axis = 0.33, axes = (0, 1, 2), skip_label = False )
    Normalize( normalize = False, data_key = 'image', metadata_key = 'metadata', scheme = 'volume_wise_znorm' )
    Skeleton( label_key = 'label', skeleton = False, do_tube = False )
    ConvertLabelsToRegions( convert_labels_to_regions = False, label_key = 'label' )
    CopyImageToLabel( copy = False, data_key = 'image', label_key = 'label' )
    DownsampleSegForDS( deep_supervision = False, label_key = 'label', factors = (1, 0.5, 0.25, 0.125, 0.0625) )
    Masking( mask = False, data_key = 'image', ratio = 0.5, token_size = 0.05, pixel_value = 'min' )
    RemoveBatchDimension( data_key = 'image', label_key = 'label' )
    <augmentations.clone_segmentation.CloneMinigioma object at 0x7f4b49157310>
)



Train dataset:  ['FOMO2_sub_1090', 'FOMO2_sub_11033', 'FOMO2_sub_6983', 'FOMO2_sub_7', 'FOMO2_sub_4335', 'FOMO2_sub_10373', 'FOMO2_sub_6673', 'FOMO2_sub_1374', 'FOMO2_sub_1994', 'FOMO2_sub_4150', 'FOMO2_sub_5694', 'FOMO2_sub_1479', 'FOMO2_sub_5700', 'FOMO2_sub_1044', 'FOMO2_sub_8012', 'FOMO2_sub_7787', 'FOMO2_sub_8553', 'FOMO2_sub_8038', 'FOMO2_sub_3979', 'FOMO2_sub_6197', 'FOMO2_sub_10828', 'FOMO2_sub_5906', 'FOMO2_sub_5760', 'FOMO2_sub_8843', 'FOMO2_sub_2145', 'FOMO2_sub_6772', 'FOMO2_sub_2185', 'FOMO2_sub_9298', 'FOMO2_sub_6963', 'FOMO2_sub_1855', 'FOMO2_sub_1334', 'FOMO2_sub_1400', 'FOMO2_sub_3385', 'FOMO2_sub_2785', 'FOMO2_sub_8658', 'FOMO2_sub_1360', 'FOMO2_sub_2910', 'FOMO2_sub_10577', 'FOMO2_sub_6462', 'FOMO2_sub_3260', 'FOMO2_sub_7102', 'FOMO2_sub_18', 'FOMO2_sub_8348', 'FOMO2_sub_633', 'FOMO2_sub_4665', 'FOMO2_sub_23', 'FOMO2_sub_1974', 'FOMO2_sub_10208', 'FOMO2_sub_8217', 'FOMO2_sub_8817', 'FOMO2_sub_8823', 'FOMO2_sub_5866', 'FOMO2_sub_3359', 'FOMO2_sub_10057', 'FOMO2_sub_7273', 'FOMO2_sub_3880', 'FOMO2_sub_1670', 'FOMO2_sub_9727', 'FOMO2_sub_2', 'FOMO2_sub_5555', 'FOMO2_sub_4190', 'FOMO2_sub_7583', 'FOMO2_sub_7623', 'FOMO2_sub_6488', 'FOMO2_sub_3530', 'FOMO2_sub_8487', 'FOMO2_sub_924', 'FOMO2_sub_3834', 'FOMO2_sub_7003', 'FOMO2_sub_1954', 'FOMO2_sub_3524', 'FOMO2_sub_10267', 'FOMO2_sub_6177', 'FOMO2_sub_262', 'FOMO2_sub_4955', 'FOMO2_sub_7702', 'FOMO2_sub_10228', 'FOMO2_sub_9957', 'FOMO2_sub_2310', 'FOMO2_sub_6547', 'FOMO2_sub_1809', 'FOMO2_sub_713', 'FOMO2_sub_4770', 'FOMO2_sub_3695', 'FOMO2_sub_7227', 'FOMO2_sub_5054', 'FOMO2_sub_878', 'FOMO2_sub_898', 'FOMO2_sub_1729', 'FOMO2_sub_8678', 'FOMO2_sub_8058', 'FOMO2_sub_6917', 'FOMO2_sub_6653', 'FOMO2_sub_10347', 'FOMO2_sub_11178', 'FOMO2_sub_4519', 'FOMO2_sub_4124', 'FOMO2_sub_91', 'FOMO2_sub_3095', 'FOMO2_sub_21', 'FOMO2_sub_8388', 'FOMO2_sub_1189', 'FOMO2_sub_10', 'FOMO2_sub_5390', 'FOMO2_sub_256', 'FOMO2_sub_6217', 'FOMO2_sub_4005', 'FOMO2_sub_16', 'FOMO2_sub_2739', 'FOMO2_sub_9008', 'FOMO2_sub_9', 'FOMO2_sub_8863', 'FOMO2_sub_5430', 'FOMO2_sub_9278', 'FOMO2_sub_7313', 'FOMO2_sub_4209', 'FOMO2_sub_10182', 'FOMO2_sub_759', 'FOMO2_sub_6382', 'FOMO2_sub_2574', 'FOMO2_sub_4480', 'FOMO2_sub_5720', 'FOMO2_sub_4784', 'FOMO2_sub_9133', 'FOMO2_sub_8988', 'FOMO2_sub_1690', 'FOMO2_sub_10558', 'FOMO2_sub_3840', 'FOMO2_sub_8243', 'FOMO2_sub_14', 'FOMO2_sub_468', 'FOMO2_sub_4975', 'FOMO2_sub_4909', 'FOMO2_sub_5', 'FOMO2_sub_2264', 'FOMO2_sub_607', 'FOMO2_sub_7477', 'FOMO2_sub_1070', 'FOMO2_sub_593', 'FOMO2_sub_7167', 'FOMO2_sub_5740', 'FOMO2_sub_779', 'FOMO2_sub_8942', 'FOMO2_sub_8717', 'FOMO2_sub_428', 'FOMO2_sub_10077', 'FOMO2_sub_10202', 'FOMO2_sub_2930', 'FOMO2_sub_10802', 'FOMO2_sub_4949', 'FOMO2_sub_6151', 'FOMO2_sub_7867', 'FOMO2_sub_4500', 'FOMO2_sub_6316', 'FOMO2_sub_1255', 'FOMO2_sub_6857', 'FOMO2_sub_1354', 'FOMO2_sub_2349', 'FOMO2_sub_7458', 'FOMO2_sub_9892', 'FOMO2_sub_1644', 'FOMO2_sub_157', 'FOMO2_sub_3049', 'FOMO2_sub_6', 'FOMO2_sub_8078', 'FOMO2_sub_5449', 'FOMO2_sub_9918', 'FOMO2_sub_6296', 'FOMO2_sub_9337', 'FOMO2_sub_8', 'FOMO2_sub_10248', 'FOMO2_sub_6508', 'FOMO2_sub_9027', 'FOMO2_sub_8223', 'FOMO2_sub_10037', 'FOMO2_sub_2039', 'FOMO2_sub_5219', 'FOMO2_sub_10887', 'FOMO2_sub_448', 'FOMO2_sub_9938', 'FOMO2_sub_1980', 'FOMO2_sub_8632', 'FOMO2_sub_2455', 'FOMO2_sub_9147', 'FOMO2_sub_5139', 'FOMO2_sub_5100', 'FOMO2_sub_8322', 'FOMO2_sub_8968', 'FOMO2_sub_2950', 'FOMO2_sub_1789', 'FOMO2_sub_5575', 'FOMO2_sub_9773', 'FOMO2_sub_2884', 'FOMO2_sub_7247', 'FOMO2_sub_5120', 'FOMO2_sub_7748', 'FOMO2_sub_9753', 'FOMO2_sub_7728', 'FOMO2_sub_10063', 'FOMO2_sub_6838', 'FOMO2_sub_3425', 'FOMO2_sub_2805', 'FOMO2_sub_7418', 'FOMO2_sub_2495', 'FOMO2_sub_10993', 'FOMO2_sub_9793', 'FOMO2_sub_8177', 'FOMO2_sub_2290', 'FOMO2_sub_10703', 'FOMO2_sub_9173', 'FOMO2_sub_10657', 'FOMO2_sub_2330', 'FOMO2_sub_739', 'FOMO2_sub_5529', 'FOMO2_sub_10222', 'FOMO2_sub_9483', 'FOMO2_sub_4625', 'FOMO2_sub_1829', 'FOMO2_sub_8533', 'FOMO2_sub_9457', 'FOMO2_sub_13', 'FOMO2_sub_4810', 'FOMO2_sub_6937', 'FOMO2_sub_2119', 'FOMO2_sub_5985', 'FOMO2_sub_3715', 'FOMO2_sub_3504', 'FOMO2_sub_1710', 'FOMO2_sub_1525', 'FOMO2_sub_7893', 'FOMO2_sub_2969', 'FOMO2_sub_11132', 'FOMO2_sub_9628', 'FOMO2_sub_4619', 'FOMO2_sub_9272', 'FOMO2_sub_6362', 'FOMO2_sub_10987', 'FOMO2_sub_4935', 'FOMO2_sub_8797', 'FOMO2_sub_12', 'FOMO2_sub_3860', 'FOMO2_sub_9898', 'FOMO2_sub_137', 'FOMO2_sub_117', 'FOMO2_sub_7603', 'FOMO2_sub_7907', 'FOMO2_sub_2924', 'FOMO2_sub_9562', 'FOMO2_sub_2600', 'FOMO2_sub_1565', 'FOMO2_sub_1419', 'FOMO2_sub_10723', 'FOMO2_sub_10538', 'FOMO2_sub_3550', 'FOMO2_sub_5364', 'FOMO2_sub_4829', 'FOMO2_sub_613', 'FOMO2_sub_858', 'FOMO2_sub_3075', 'FOMO2_sub_6342', 'FOMO2_sub_6045', 'FOMO2_sub_1545', 'FOMO2_sub_9608', 'FOMO2_sub_4045', 'FOMO2_sub_4599', 'FOMO2_sub_4790', 'FOMO2_sub_3220', 'FOMO2_sub_547', 'FOMO2_sub_11158', 'FOMO2_sub_11112', 'FOMO2_sub_6051', 'FOMO2_sub_4645', 'FOMO2_sub_9443', 'FOMO2_sub_1', 'FOMO2_sub_2759', 'FOMO2_sub_3', 'FOMO2_sub_8407', 'FOMO2_sub_4434', 'FOMO2_sub_19', 'FOMO2_sub_4144', 'FOMO2_sub_3240', 'FOMO2_sub_282', 'FOMO2_sub_6031', 'FOMO2_sub_944', 'FOMO2_sub_4460', 'FOMO2_sub_4', 'FOMO2_sub_6005', 'FOMO2_sub_10848', 'FOMO2_sub_5840', 'FOMO2_sub_4355']
Val dataset:  ['FOMO2_sub_1050', 'FOMO2_sub_2765', 'FOMO2_sub_11', 'FOMO2_sub_3814', 'FOMO2_sub_3279', 'FOMO2_sub_2000', 'FOMO2_sub_10822', 'FOMO2_sub_5285', 'FOMO2_sub_3669', 'FOMO2_sub_302', 'FOMO2_sub_3899', 'FOMO2_sub_4170', 'FOMO2_sub_3570', 'FOMO2_sub_7148', 'FOMO2_sub_7933', 'FOMO2_sub_4025', 'FOMO2_sub_15', 'FOMO2_sub_2020', 'FOMO2_sub_1215', 'FOMO2_sub_6798', 'FOMO2_sub_10518', 'FOMO2_sub_5886', 'FOMO2_sub_9463', 'FOMO2_sub_5410', 'FOMO2_sub_904', 'FOMO2_sub_4744', 'FOMO2_sub_10393', 'FOMO2_sub_5595', 'FOMO2_sub_3194', 'FOMO2_sub_5245', 'FOMO2_sub_1380', 'FOMO2_sub_17', 'FOMO2_sub_322', 'FOMO2_sub_9647', 'FOMO2_sub_5080', 'FOMO2_sub_7438', 'FOMO2_sub_4315', 'FOMO2_sub_8368', 'FOMO2_sub_22', 'FOMO2_sub_2640', 'FOMO2_sub_7108', 'FOMO2_sub_8097', 'FOMO2_sub_6693', 'FOMO2_sub_9107', 'FOMO2_sub_9153', 'FOMO2_sub_10683', 'FOMO2_sub_3115', 'FOMO2_sub_11138', 'FOMO2_sub_20', 'FOMO2_sub_4764', 'FOMO2_sub_10103', 'FOMO2_sub_5674', 'FOMO2_sub_2165', 'FOMO2_sub_9252', 'FOMO2_sub_7082', 'FOMO2_sub_236', 'FOMO2_sub_10512', 'FOMO2_sub_1109', 'FOMO2_sub_7293', 'FOMO2_sub_4454', 'FOMO2_sub_9318', 'FOMO2_sub_7128', 'FOMO2_sub_6818', 'FOMO2_sub_2659', 'FOMO2_sub_8203', 'FOMO2_sub_3589', 'FOMO2_sub_1235', 'FOMO2_sub_9582', 'FOMO2_sub_5265', 'FOMO2_sub_5404', 'FOMO2_sub_8698', 'FOMO2_sub_11013', 'FOMO2_sub_2475']
Run type:  finetune
Starting training with 50000 max iterations over 500 epochs with train dataset of size 290 datapoints and val dataset of size 73 and effective batch size of 4
Loading Model: 3D unet_xl
Found model class:  <function unet_xl at 0x7f4b4a35a710>
MODALITIES 3
Transferring weights for finetuning
Checkpoint path: None
Loading from PyTorch Lightning checkpoint

  | Name          | Type             | Params | Mode 
-----------------------------------------------------------
0 | train_metrics | MetricCollection | 0      | train
1 | val_metrics   | MetricCollection | 0      | train
2 | model         | UNet             | 90.3 M | train
3 | loss_fn_train | DiceCE           | 0      | train
4 | loss_fn_val   | DiceCE           | 0      | train
-----------------------------------------------------------
90.3 M    Trainable params
0         Non-trainable params
90.3 M    Total params
361.232   Total estimated model params size (MB)
105       Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Using num_workers: 8, num_devices: 1
Task type: segmentation
ARGS: Namespace(data_dir='/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed', save_dir='/dss/dsshome1/04/ra58seq2/unet/finetuned/t2', pretrained_weights_path='/dss/dsshome1/04/ra58seq2/unet/models/FOMO60k/unet_xl_lw_dec/versions/version_0/epoch=99.ckpt', model_name='unet_xl', precision='bf16-mixed', patch_size=96, learning_rate=0.0001, compile=False, compile_mode=None, num_devices=1, num_workers=8, fast_dev_run=False, new_version=True, augmentation_preset='clone_all', epochs=500, batch_size=4, train_batches_per_epoch=100, taskid=2, split_method='simple_train_val_split', split_param=0.2, split_idx=0, experiment='finetuning with larger artificial dataset')
{'clone_minigioma_p_per_sample': 1.0, 'normalize': False}
Composing Transforms



Compose(
    CollectMetadata( data_key = 'image', label_key = 'label' )
    AddBatchDimension( data_key = 'image', label_key = 'label' )
    Spatial( data_key = 'image', label_key = 'label', skip_label = False, order = 3, do_crop = True, cval = 'min', patch_size = (96, 96, 96), random_crop = False, clip_to_input_range = False, p_deform_per_sample = 0.33, deform_sigma = (20, 30), deform_alpha = (200, 600), p_rot_per_sample = 0.2, p_rot_per_axis = 0.66, x_rot_in_degrees = (-30.0, 30.0), y_rot_in_degrees = (-30.0, 30.0), z_rot_in_degrees = (-30.0, 30.0), p_scale_per_sample = 0.2, scale_factor = (0.9, 1.1) )
    AdditiveNoise( data_key = 'image', p_per_sample = 0.2, mean = (0.0, 0.0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    Blur( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, sigma = (0.0, 1.0), clip_to_input_range = False )
    MultiplicativeNoise( data_key = 'image', p_per_sample = 0.2, mean = (0, 0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    MotionGhosting( data_key = 'image', p_per_sample = 0.2, alpha = (0.85, 0.95), num_reps = (2, 11), axes = (0, 3), clip_to_input_range = False )
    GibbsRinging( data_key = 'image', p_per_sample = 0.2, cut_freq = (96, 129), axes = (0, 3), clip_to_input_range = False )
    SimulateLowres( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, p_per_axis = 0.33, zoom_range = (0.5, 1.0), clip_to_input_range = False )
    BiasField( data_key = 'image', p_per_sample = 0.33, clip_to_input_range = False )
    Gamma( data_key = 'image', p_per_sample = 0.2, gamma_range = (0.5, 2.0), p_invert_image = 0.05, per_channel = True, clip_to_input_range = False )
    Mirror( data_key = 'image', label_key = 'label', p_per_sample = 0.0, p_mirror_per_axis = 0.33, axes = (0, 1, 2), skip_label = False )
    Normalize( normalize = False, data_key = 'image', metadata_key = 'metadata', scheme = 'volume_wise_znorm' )
    Skeleton( label_key = 'label', skeleton = False, do_tube = False )
    ConvertLabelsToRegions( convert_labels_to_regions = False, label_key = 'label' )
    CopyImageToLabel( copy = False, data_key = 'image', label_key = 'label' )
    DownsampleSegForDS( deep_supervision = False, label_key = 'label', factors = (1, 0.5, 0.25, 0.125, 0.0625) )
    Masking( mask = False, data_key = 'image', ratio = 0.5, token_size = 0.05, pixel_value = 'min' )
    RemoveBatchDimension( data_key = 'image', label_key = 'label' )
    <augmentations.clone_segmentation.CloneMinigioma object at 0x7f79261973d0>
)



Train dataset:  ['FOMO2_sub_1090', 'FOMO2_sub_11033', 'FOMO2_sub_6983', 'FOMO2_sub_7', 'FOMO2_sub_4335', 'FOMO2_sub_10373', 'FOMO2_sub_6673', 'FOMO2_sub_1374', 'FOMO2_sub_1994', 'FOMO2_sub_4150', 'FOMO2_sub_5694', 'FOMO2_sub_1479', 'FOMO2_sub_5700', 'FOMO2_sub_1044', 'FOMO2_sub_8012', 'FOMO2_sub_7787', 'FOMO2_sub_8553', 'FOMO2_sub_8038', 'FOMO2_sub_3979', 'FOMO2_sub_6197', 'FOMO2_sub_10828', 'FOMO2_sub_5906', 'FOMO2_sub_5760', 'FOMO2_sub_8843', 'FOMO2_sub_2145', 'FOMO2_sub_6772', 'FOMO2_sub_2185', 'FOMO2_sub_9298', 'FOMO2_sub_6963', 'FOMO2_sub_1855', 'FOMO2_sub_1334', 'FOMO2_sub_1400', 'FOMO2_sub_3385', 'FOMO2_sub_2785', 'FOMO2_sub_8658', 'FOMO2_sub_1360', 'FOMO2_sub_2910', 'FOMO2_sub_10577', 'FOMO2_sub_6462', 'FOMO2_sub_3260', 'FOMO2_sub_7102', 'FOMO2_sub_18', 'FOMO2_sub_8348', 'FOMO2_sub_633', 'FOMO2_sub_4665', 'FOMO2_sub_23', 'FOMO2_sub_1974', 'FOMO2_sub_10208', 'FOMO2_sub_8217', 'FOMO2_sub_8817', 'FOMO2_sub_8823', 'FOMO2_sub_5866', 'FOMO2_sub_3359', 'FOMO2_sub_10057', 'FOMO2_sub_7273', 'FOMO2_sub_3880', 'FOMO2_sub_1670', 'FOMO2_sub_9727', 'FOMO2_sub_2', 'FOMO2_sub_5555', 'FOMO2_sub_4190', 'FOMO2_sub_7583', 'FOMO2_sub_7623', 'FOMO2_sub_6488', 'FOMO2_sub_3530', 'FOMO2_sub_8487', 'FOMO2_sub_924', 'FOMO2_sub_3834', 'FOMO2_sub_7003', 'FOMO2_sub_1954', 'FOMO2_sub_3524', 'FOMO2_sub_10267', 'FOMO2_sub_6177', 'FOMO2_sub_262', 'FOMO2_sub_4955', 'FOMO2_sub_7702', 'FOMO2_sub_10228', 'FOMO2_sub_9957', 'FOMO2_sub_2310', 'FOMO2_sub_6547', 'FOMO2_sub_1809', 'FOMO2_sub_713', 'FOMO2_sub_4770', 'FOMO2_sub_3695', 'FOMO2_sub_7227', 'FOMO2_sub_5054', 'FOMO2_sub_878', 'FOMO2_sub_898', 'FOMO2_sub_1729', 'FOMO2_sub_8678', 'FOMO2_sub_8058', 'FOMO2_sub_6917', 'FOMO2_sub_6653', 'FOMO2_sub_10347', 'FOMO2_sub_11178', 'FOMO2_sub_4519', 'FOMO2_sub_4124', 'FOMO2_sub_91', 'FOMO2_sub_3095', 'FOMO2_sub_21', 'FOMO2_sub_8388', 'FOMO2_sub_1189', 'FOMO2_sub_10', 'FOMO2_sub_5390', 'FOMO2_sub_256', 'FOMO2_sub_6217', 'FOMO2_sub_4005', 'FOMO2_sub_16', 'FOMO2_sub_2739', 'FOMO2_sub_9008', 'FOMO2_sub_9', 'FOMO2_sub_8863', 'FOMO2_sub_5430', 'FOMO2_sub_9278', 'FOMO2_sub_7313', 'FOMO2_sub_4209', 'FOMO2_sub_10182', 'FOMO2_sub_759', 'FOMO2_sub_6382', 'FOMO2_sub_2574', 'FOMO2_sub_4480', 'FOMO2_sub_5720', 'FOMO2_sub_4784', 'FOMO2_sub_9133', 'FOMO2_sub_8988', 'FOMO2_sub_1690', 'FOMO2_sub_10558', 'FOMO2_sub_3840', 'FOMO2_sub_8243', 'FOMO2_sub_14', 'FOMO2_sub_468', 'FOMO2_sub_4975', 'FOMO2_sub_4909', 'FOMO2_sub_5', 'FOMO2_sub_2264', 'FOMO2_sub_607', 'FOMO2_sub_7477', 'FOMO2_sub_1070', 'FOMO2_sub_593', 'FOMO2_sub_7167', 'FOMO2_sub_5740', 'FOMO2_sub_779', 'FOMO2_sub_8942', 'FOMO2_sub_8717', 'FOMO2_sub_428', 'FOMO2_sub_10077', 'FOMO2_sub_10202', 'FOMO2_sub_2930', 'FOMO2_sub_10802', 'FOMO2_sub_4949', 'FOMO2_sub_6151', 'FOMO2_sub_7867', 'FOMO2_sub_4500', 'FOMO2_sub_6316', 'FOMO2_sub_1255', 'FOMO2_sub_6857', 'FOMO2_sub_1354', 'FOMO2_sub_2349', 'FOMO2_sub_7458', 'FOMO2_sub_9892', 'FOMO2_sub_1644', 'FOMO2_sub_157', 'FOMO2_sub_3049', 'FOMO2_sub_6', 'FOMO2_sub_8078', 'FOMO2_sub_5449', 'FOMO2_sub_9918', 'FOMO2_sub_6296', 'FOMO2_sub_9337', 'FOMO2_sub_8', 'FOMO2_sub_10248', 'FOMO2_sub_6508', 'FOMO2_sub_9027', 'FOMO2_sub_8223', 'FOMO2_sub_10037', 'FOMO2_sub_2039', 'FOMO2_sub_5219', 'FOMO2_sub_10887', 'FOMO2_sub_448', 'FOMO2_sub_9938', 'FOMO2_sub_1980', 'FOMO2_sub_8632', 'FOMO2_sub_2455', 'FOMO2_sub_9147', 'FOMO2_sub_5139', 'FOMO2_sub_5100', 'FOMO2_sub_8322', 'FOMO2_sub_8968', 'FOMO2_sub_2950', 'FOMO2_sub_1789', 'FOMO2_sub_5575', 'FOMO2_sub_9773', 'FOMO2_sub_2884', 'FOMO2_sub_7247', 'FOMO2_sub_5120', 'FOMO2_sub_7748', 'FOMO2_sub_9753', 'FOMO2_sub_7728', 'FOMO2_sub_10063', 'FOMO2_sub_6838', 'FOMO2_sub_3425', 'FOMO2_sub_2805', 'FOMO2_sub_7418', 'FOMO2_sub_2495', 'FOMO2_sub_10993', 'FOMO2_sub_9793', 'FOMO2_sub_8177', 'FOMO2_sub_2290', 'FOMO2_sub_10703', 'FOMO2_sub_9173', 'FOMO2_sub_10657', 'FOMO2_sub_2330', 'FOMO2_sub_739', 'FOMO2_sub_5529', 'FOMO2_sub_10222', 'FOMO2_sub_9483', 'FOMO2_sub_4625', 'FOMO2_sub_1829', 'FOMO2_sub_8533', 'FOMO2_sub_9457', 'FOMO2_sub_13', 'FOMO2_sub_4810', 'FOMO2_sub_6937', 'FOMO2_sub_2119', 'FOMO2_sub_5985', 'FOMO2_sub_3715', 'FOMO2_sub_3504', 'FOMO2_sub_1710', 'FOMO2_sub_1525', 'FOMO2_sub_7893', 'FOMO2_sub_2969', 'FOMO2_sub_11132', 'FOMO2_sub_9628', 'FOMO2_sub_4619', 'FOMO2_sub_9272', 'FOMO2_sub_6362', 'FOMO2_sub_10987', 'FOMO2_sub_4935', 'FOMO2_sub_8797', 'FOMO2_sub_12', 'FOMO2_sub_3860', 'FOMO2_sub_9898', 'FOMO2_sub_137', 'FOMO2_sub_117', 'FOMO2_sub_7603', 'FOMO2_sub_7907', 'FOMO2_sub_2924', 'FOMO2_sub_9562', 'FOMO2_sub_2600', 'FOMO2_sub_1565', 'FOMO2_sub_1419', 'FOMO2_sub_10723', 'FOMO2_sub_10538', 'FOMO2_sub_3550', 'FOMO2_sub_5364', 'FOMO2_sub_4829', 'FOMO2_sub_613', 'FOMO2_sub_858', 'FOMO2_sub_3075', 'FOMO2_sub_6342', 'FOMO2_sub_6045', 'FOMO2_sub_1545', 'FOMO2_sub_9608', 'FOMO2_sub_4045', 'FOMO2_sub_4599', 'FOMO2_sub_4790', 'FOMO2_sub_3220', 'FOMO2_sub_547', 'FOMO2_sub_11158', 'FOMO2_sub_11112', 'FOMO2_sub_6051', 'FOMO2_sub_4645', 'FOMO2_sub_9443', 'FOMO2_sub_1', 'FOMO2_sub_2759', 'FOMO2_sub_3', 'FOMO2_sub_8407', 'FOMO2_sub_4434', 'FOMO2_sub_19', 'FOMO2_sub_4144', 'FOMO2_sub_3240', 'FOMO2_sub_282', 'FOMO2_sub_6031', 'FOMO2_sub_944', 'FOMO2_sub_4460', 'FOMO2_sub_4', 'FOMO2_sub_6005', 'FOMO2_sub_10848', 'FOMO2_sub_5840', 'FOMO2_sub_4355']
Val dataset:  ['FOMO2_sub_1050', 'FOMO2_sub_2765', 'FOMO2_sub_11', 'FOMO2_sub_3814', 'FOMO2_sub_3279', 'FOMO2_sub_2000', 'FOMO2_sub_10822', 'FOMO2_sub_5285', 'FOMO2_sub_3669', 'FOMO2_sub_302', 'FOMO2_sub_3899', 'FOMO2_sub_4170', 'FOMO2_sub_3570', 'FOMO2_sub_7148', 'FOMO2_sub_7933', 'FOMO2_sub_4025', 'FOMO2_sub_15', 'FOMO2_sub_2020', 'FOMO2_sub_1215', 'FOMO2_sub_6798', 'FOMO2_sub_10518', 'FOMO2_sub_5886', 'FOMO2_sub_9463', 'FOMO2_sub_5410', 'FOMO2_sub_904', 'FOMO2_sub_4744', 'FOMO2_sub_10393', 'FOMO2_sub_5595', 'FOMO2_sub_3194', 'FOMO2_sub_5245', 'FOMO2_sub_1380', 'FOMO2_sub_17', 'FOMO2_sub_322', 'FOMO2_sub_9647', 'FOMO2_sub_5080', 'FOMO2_sub_7438', 'FOMO2_sub_4315', 'FOMO2_sub_8368', 'FOMO2_sub_22', 'FOMO2_sub_2640', 'FOMO2_sub_7108', 'FOMO2_sub_8097', 'FOMO2_sub_6693', 'FOMO2_sub_9107', 'FOMO2_sub_9153', 'FOMO2_sub_10683', 'FOMO2_sub_3115', 'FOMO2_sub_11138', 'FOMO2_sub_20', 'FOMO2_sub_4764', 'FOMO2_sub_10103', 'FOMO2_sub_5674', 'FOMO2_sub_2165', 'FOMO2_sub_9252', 'FOMO2_sub_7082', 'FOMO2_sub_236', 'FOMO2_sub_10512', 'FOMO2_sub_1109', 'FOMO2_sub_7293', 'FOMO2_sub_4454', 'FOMO2_sub_9318', 'FOMO2_sub_7128', 'FOMO2_sub_6818', 'FOMO2_sub_2659', 'FOMO2_sub_8203', 'FOMO2_sub_3589', 'FOMO2_sub_1235', 'FOMO2_sub_9582', 'FOMO2_sub_5265', 'FOMO2_sub_5404', 'FOMO2_sub_8698', 'FOMO2_sub_11013', 'FOMO2_sub_2475']
Run type:  finetune
Starting training with 50000 max iterations over 500 epochs with train dataset of size 290 datapoints and val dataset of size 73 and effective batch size of 4
Loading Model: 3D unet_xl
Found model class:  <function unet_xl at 0x7f79273b2710>
MODALITIES 3
Transferring weights for finetuning
Checkpoint path: None
Loading from PyTorch Lightning checkpoint
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in ./wandb/run-20250731_200004-8ctu1p47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run finetune_unet_xl_finetuning with larger artificial dataset_2_version_34
wandb:  View project at https://wandb.ai/daniel-gloukhman-ludwig-maximilianuniversity-of-munich/fomo-finetuning
wandb:  View run at https://wandb.ai/daniel-gloukhman-ludwig-maximilianuniversity-of-munich/fomo-finetuning/runs/8ctu1p47
INFO:root:Setting up data for stage: fit
INFO:root:Validating on samples: ['/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1050', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2765', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3814', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3279', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2000', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10822', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5285', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3669', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_302', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3899', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4170', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3570', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7148', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7933', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4025', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_15', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2020', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1215', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6798', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10518', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5886', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9463', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5410', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_904', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4744', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10393', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5595', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3194', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5245', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1380', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_17', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_322', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9647', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5080', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7438', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4315', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8368', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_22', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2640', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7108', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8097', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6693', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9107', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9153', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10683', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3115', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11138', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_20', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4764', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10103', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5674', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2165', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9252', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7082', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_236', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_10512', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1109', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7293', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_4454', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9318', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_7128', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_6818', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2659', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8203', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_3589', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_1235', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_9582', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5265', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_5404', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_8698', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_11013', '/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2/FOMO2_sub_2475']
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name          | Type             | Params | Mode 
-----------------------------------------------------------
0 | train_metrics | MetricCollection | 0      | train
1 | val_metrics   | MetricCollection | 0      | train
2 | model         | UNet             | 90.3 M | train
3 | loss_fn_train | DiceCE           | 0      | train
4 | loss_fn_val   | DiceCE           | 0      | train
-----------------------------------------------------------
90.3 M    Trainable params
0         Non-trainable params
90.3 M    Total params
361.232   Total estimated model params size (MB)
105       Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Using num_workers: 8, num_devices: 1
Task type: segmentation
ARGS: Namespace(data_dir='/dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed', save_dir='/dss/dsshome1/04/ra58seq2/unet/finetuned/t2', pretrained_weights_path='/dss/dsshome1/04/ra58seq2/unet/models/FOMO60k/unet_xl_lw_dec/versions/version_0/epoch=99.ckpt', model_name='unet_xl', precision='bf16-mixed', patch_size=96, learning_rate=0.0001, compile=False, compile_mode=None, num_devices=1, num_workers=8, fast_dev_run=False, new_version=True, augmentation_preset='clone_all', epochs=500, batch_size=4, train_batches_per_epoch=100, taskid=2, split_method='simple_train_val_split', split_param=0.2, split_idx=0, experiment='finetuning with larger artificial dataset')
{'clone_minigioma_p_per_sample': 1.0, 'normalize': False}
Composing Transforms



Compose(
    CollectMetadata( data_key = 'image', label_key = 'label' )
    AddBatchDimension( data_key = 'image', label_key = 'label' )
    Spatial( data_key = 'image', label_key = 'label', skip_label = False, order = 3, do_crop = True, cval = 'min', patch_size = (96, 96, 96), random_crop = False, clip_to_input_range = False, p_deform_per_sample = 0.33, deform_sigma = (20, 30), deform_alpha = (200, 600), p_rot_per_sample = 0.2, p_rot_per_axis = 0.66, x_rot_in_degrees = (-30.0, 30.0), y_rot_in_degrees = (-30.0, 30.0), z_rot_in_degrees = (-30.0, 30.0), p_scale_per_sample = 0.2, scale_factor = (0.9, 1.1) )
    AdditiveNoise( data_key = 'image', p_per_sample = 0.2, mean = (0.0, 0.0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    Blur( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, sigma = (0.0, 1.0), clip_to_input_range = False )
    MultiplicativeNoise( data_key = 'image', p_per_sample = 0.2, mean = (0, 0), sigma = (0.001, 0.0001), clip_to_input_range = False )
    MotionGhosting( data_key = 'image', p_per_sample = 0.2, alpha = (0.85, 0.95), num_reps = (2, 11), axes = (0, 3), clip_to_input_range = False )
    GibbsRinging( data_key = 'image', p_per_sample = 0.2, cut_freq = (96, 129), axes = (0, 3), clip_to_input_range = False )
    SimulateLowres( data_key = 'image', p_per_sample = 0.2, p_per_channel = 0.5, p_per_axis = 0.33, zoom_range = (0.5, 1.0), clip_to_input_range = False )
    BiasField( data_key = 'image', p_per_sample = 0.33, clip_to_input_range = False )
    Gamma( data_key = 'image', p_per_sample = 0.2, gamma_range = (0.5, 2.0), p_invert_image = 0.05, per_channel = True, clip_to_input_range = False )
    Mirror( data_key = 'image', label_key = 'label', p_per_sample = 0.0, p_mirror_per_axis = 0.33, axes = (0, 1, 2), skip_label = False )
    Normalize( normalize = False, data_key = 'image', metadata_key = 'metadata', scheme = 'volume_wise_znorm' )
    Skeleton( label_key = 'label', skeleton = False, do_tube = False )
    ConvertLabelsToRegions( convert_labels_to_regions = False, label_key = 'label' )
    CopyImageToLabel( copy = False, data_key = 'image', label_key = 'label' )
    DownsampleSegForDS( deep_supervision = False, label_key = 'label', factors = (1, 0.5, 0.25, 0.125, 0.0625) )
    Masking( mask = False, data_key = 'image', ratio = 0.5, token_size = 0.05, pixel_value = 'min' )
    RemoveBatchDimension( data_key = 'image', label_key = 'label' )
    <augmentations.clone_segmentation.CloneMinigioma object at 0x7f7fdb050be0>
)



Train dataset:  ['FOMO2_sub_1090', 'FOMO2_sub_11033', 'FOMO2_sub_6983', 'FOMO2_sub_7', 'FOMO2_sub_4335', 'FOMO2_sub_10373', 'FOMO2_sub_6673', 'FOMO2_sub_1374', 'FOMO2_sub_1994', 'FOMO2_sub_4150', 'FOMO2_sub_5694', 'FOMO2_sub_1479', 'FOMO2_sub_5700', 'FOMO2_sub_1044', 'FOMO2_sub_8012', 'FOMO2_sub_7787', 'FOMO2_sub_8553', 'FOMO2_sub_8038', 'FOMO2_sub_3979', 'FOMO2_sub_6197', 'FOMO2_sub_10828', 'FOMO2_sub_5906', 'FOMO2_sub_5760', 'FOMO2_sub_8843', 'FOMO2_sub_2145', 'FOMO2_sub_6772', 'FOMO2_sub_2185', 'FOMO2_sub_9298', 'FOMO2_sub_6963', 'FOMO2_sub_1855', 'FOMO2_sub_1334', 'FOMO2_sub_1400', 'FOMO2_sub_3385', 'FOMO2_sub_2785', 'FOMO2_sub_8658', 'FOMO2_sub_1360', 'FOMO2_sub_2910', 'FOMO2_sub_10577', 'FOMO2_sub_6462', 'FOMO2_sub_3260', 'FOMO2_sub_7102', 'FOMO2_sub_18', 'FOMO2_sub_8348', 'FOMO2_sub_633', 'FOMO2_sub_4665', 'FOMO2_sub_23', 'FOMO2_sub_1974', 'FOMO2_sub_10208', 'FOMO2_sub_8217', 'FOMO2_sub_8817', 'FOMO2_sub_8823', 'FOMO2_sub_5866', 'FOMO2_sub_3359', 'FOMO2_sub_10057', 'FOMO2_sub_7273', 'FOMO2_sub_3880', 'FOMO2_sub_1670', 'FOMO2_sub_9727', 'FOMO2_sub_2', 'FOMO2_sub_5555', 'FOMO2_sub_4190', 'FOMO2_sub_7583', 'FOMO2_sub_7623', 'FOMO2_sub_6488', 'FOMO2_sub_3530', 'FOMO2_sub_8487', 'FOMO2_sub_924', 'FOMO2_sub_3834', 'FOMO2_sub_7003', 'FOMO2_sub_1954', 'FOMO2_sub_3524', 'FOMO2_sub_10267', 'FOMO2_sub_6177', 'FOMO2_sub_262', 'FOMO2_sub_4955', 'FOMO2_sub_7702', 'FOMO2_sub_10228', 'FOMO2_sub_9957', 'FOMO2_sub_2310', 'FOMO2_sub_6547', 'FOMO2_sub_1809', 'FOMO2_sub_713', 'FOMO2_sub_4770', 'FOMO2_sub_3695', 'FOMO2_sub_7227', 'FOMO2_sub_5054', 'FOMO2_sub_878', 'FOMO2_sub_898', 'FOMO2_sub_1729', 'FOMO2_sub_8678', 'FOMO2_sub_8058', 'FOMO2_sub_6917', 'FOMO2_sub_6653', 'FOMO2_sub_10347', 'FOMO2_sub_11178', 'FOMO2_sub_4519', 'FOMO2_sub_4124', 'FOMO2_sub_91', 'FOMO2_sub_3095', 'FOMO2_sub_21', 'FOMO2_sub_8388', 'FOMO2_sub_1189', 'FOMO2_sub_10', 'FOMO2_sub_5390', 'FOMO2_sub_256', 'FOMO2_sub_6217', 'FOMO2_sub_4005', 'FOMO2_sub_16', 'FOMO2_sub_2739', 'FOMO2_sub_9008', 'FOMO2_sub_9', 'FOMO2_sub_8863', 'FOMO2_sub_5430', 'FOMO2_sub_9278', 'FOMO2_sub_7313', 'FOMO2_sub_4209', 'FOMO2_sub_10182', 'FOMO2_sub_759', 'FOMO2_sub_6382', 'FOMO2_sub_2574', 'FOMO2_sub_4480', 'FOMO2_sub_5720', 'FOMO2_sub_4784', 'FOMO2_sub_9133', 'FOMO2_sub_8988', 'FOMO2_sub_1690', 'FOMO2_sub_10558', 'FOMO2_sub_3840', 'FOMO2_sub_8243', 'FOMO2_sub_14', 'FOMO2_sub_468', 'FOMO2_sub_4975', 'FOMO2_sub_4909', 'FOMO2_sub_5', 'FOMO2_sub_2264', 'FOMO2_sub_607', 'FOMO2_sub_7477', 'FOMO2_sub_1070', 'FOMO2_sub_593', 'FOMO2_sub_7167', 'FOMO2_sub_5740', 'FOMO2_sub_779', 'FOMO2_sub_8942', 'FOMO2_sub_8717', 'FOMO2_sub_428', 'FOMO2_sub_10077', 'FOMO2_sub_10202', 'FOMO2_sub_2930', 'FOMO2_sub_10802', 'FOMO2_sub_4949', 'FOMO2_sub_6151', 'FOMO2_sub_7867', 'FOMO2_sub_4500', 'FOMO2_sub_6316', 'FOMO2_sub_1255', 'FOMO2_sub_6857', 'FOMO2_sub_1354', 'FOMO2_sub_2349', 'FOMO2_sub_7458', 'FOMO2_sub_9892', 'FOMO2_sub_1644', 'FOMO2_sub_157', 'FOMO2_sub_3049', 'FOMO2_sub_6', 'FOMO2_sub_8078', 'FOMO2_sub_5449', 'FOMO2_sub_9918', 'FOMO2_sub_6296', 'FOMO2_sub_9337', 'FOMO2_sub_8', 'FOMO2_sub_10248', 'FOMO2_sub_6508', 'FOMO2_sub_9027', 'FOMO2_sub_8223', 'FOMO2_sub_10037', 'FOMO2_sub_2039', 'FOMO2_sub_5219', 'FOMO2_sub_10887', 'FOMO2_sub_448', 'FOMO2_sub_9938', 'FOMO2_sub_1980', 'FOMO2_sub_8632', 'FOMO2_sub_2455', 'FOMO2_sub_9147', 'FOMO2_sub_5139', 'FOMO2_sub_5100', 'FOMO2_sub_8322', 'FOMO2_sub_8968', 'FOMO2_sub_2950', 'FOMO2_sub_1789', 'FOMO2_sub_5575', 'FOMO2_sub_9773', 'FOMO2_sub_2884', 'FOMO2_sub_7247', 'FOMO2_sub_5120', 'FOMO2_sub_7748', 'FOMO2_sub_9753', 'FOMO2_sub_7728', 'FOMO2_sub_10063', 'FOMO2_sub_6838', 'FOMO2_sub_3425', 'FOMO2_sub_2805', 'FOMO2_sub_7418', 'FOMO2_sub_2495', 'FOMO2_sub_10993', 'FOMO2_sub_9793', 'FOMO2_sub_8177', 'FOMO2_sub_2290', 'FOMO2_sub_10703', 'FOMO2_sub_9173', 'FOMO2_sub_10657', 'FOMO2_sub_2330', 'FOMO2_sub_739', 'FOMO2_sub_5529', 'FOMO2_sub_10222', 'FOMO2_sub_9483', 'FOMO2_sub_4625', 'FOMO2_sub_1829', 'FOMO2_sub_8533', 'FOMO2_sub_9457', 'FOMO2_sub_13', 'FOMO2_sub_4810', 'FOMO2_sub_6937', 'FOMO2_sub_2119', 'FOMO2_sub_5985', 'FOMO2_sub_3715', 'FOMO2_sub_3504', 'FOMO2_sub_1710', 'FOMO2_sub_1525', 'FOMO2_sub_7893', 'FOMO2_sub_2969', 'FOMO2_sub_11132', 'FOMO2_sub_9628', 'FOMO2_sub_4619', 'FOMO2_sub_9272', 'FOMO2_sub_6362', 'FOMO2_sub_10987', 'FOMO2_sub_4935', 'FOMO2_sub_8797', 'FOMO2_sub_12', 'FOMO2_sub_3860', 'FOMO2_sub_9898', 'FOMO2_sub_137', 'FOMO2_sub_117', 'FOMO2_sub_7603', 'FOMO2_sub_7907', 'FOMO2_sub_2924', 'FOMO2_sub_9562', 'FOMO2_sub_2600', 'FOMO2_sub_1565', 'FOMO2_sub_1419', 'FOMO2_sub_10723', 'FOMO2_sub_10538', 'FOMO2_sub_3550', 'FOMO2_sub_5364', 'FOMO2_sub_4829', 'FOMO2_sub_613', 'FOMO2_sub_858', 'FOMO2_sub_3075', 'FOMO2_sub_6342', 'FOMO2_sub_6045', 'FOMO2_sub_1545', 'FOMO2_sub_9608', 'FOMO2_sub_4045', 'FOMO2_sub_4599', 'FOMO2_sub_4790', 'FOMO2_sub_3220', 'FOMO2_sub_547', 'FOMO2_sub_11158', 'FOMO2_sub_11112', 'FOMO2_sub_6051', 'FOMO2_sub_4645', 'FOMO2_sub_9443', 'FOMO2_sub_1', 'FOMO2_sub_2759', 'FOMO2_sub_3', 'FOMO2_sub_8407', 'FOMO2_sub_4434', 'FOMO2_sub_19', 'FOMO2_sub_4144', 'FOMO2_sub_3240', 'FOMO2_sub_282', 'FOMO2_sub_6031', 'FOMO2_sub_944', 'FOMO2_sub_4460', 'FOMO2_sub_4', 'FOMO2_sub_6005', 'FOMO2_sub_10848', 'FOMO2_sub_5840', 'FOMO2_sub_4355']
Val dataset:  ['FOMO2_sub_1050', 'FOMO2_sub_2765', 'FOMO2_sub_11', 'FOMO2_sub_3814', 'FOMO2_sub_3279', 'FOMO2_sub_2000', 'FOMO2_sub_10822', 'FOMO2_sub_5285', 'FOMO2_sub_3669', 'FOMO2_sub_302', 'FOMO2_sub_3899', 'FOMO2_sub_4170', 'FOMO2_sub_3570', 'FOMO2_sub_7148', 'FOMO2_sub_7933', 'FOMO2_sub_4025', 'FOMO2_sub_15', 'FOMO2_sub_2020', 'FOMO2_sub_1215', 'FOMO2_sub_6798', 'FOMO2_sub_10518', 'FOMO2_sub_5886', 'FOMO2_sub_9463', 'FOMO2_sub_5410', 'FOMO2_sub_904', 'FOMO2_sub_4744', 'FOMO2_sub_10393', 'FOMO2_sub_5595', 'FOMO2_sub_3194', 'FOMO2_sub_5245', 'FOMO2_sub_1380', 'FOMO2_sub_17', 'FOMO2_sub_322', 'FOMO2_sub_9647', 'FOMO2_sub_5080', 'FOMO2_sub_7438', 'FOMO2_sub_4315', 'FOMO2_sub_8368', 'FOMO2_sub_22', 'FOMO2_sub_2640', 'FOMO2_sub_7108', 'FOMO2_sub_8097', 'FOMO2_sub_6693', 'FOMO2_sub_9107', 'FOMO2_sub_9153', 'FOMO2_sub_10683', 'FOMO2_sub_3115', 'FOMO2_sub_11138', 'FOMO2_sub_20', 'FOMO2_sub_4764', 'FOMO2_sub_10103', 'FOMO2_sub_5674', 'FOMO2_sub_2165', 'FOMO2_sub_9252', 'FOMO2_sub_7082', 'FOMO2_sub_236', 'FOMO2_sub_10512', 'FOMO2_sub_1109', 'FOMO2_sub_7293', 'FOMO2_sub_4454', 'FOMO2_sub_9318', 'FOMO2_sub_7128', 'FOMO2_sub_6818', 'FOMO2_sub_2659', 'FOMO2_sub_8203', 'FOMO2_sub_3589', 'FOMO2_sub_1235', 'FOMO2_sub_9582', 'FOMO2_sub_5265', 'FOMO2_sub_5404', 'FOMO2_sub_8698', 'FOMO2_sub_11013', 'FOMO2_sub_2475']
Run type:  finetune
Starting training with 50000 max iterations over 500 epochs with train dataset of size 290 datapoints and val dataset of size 73 and effective batch size of 4
Loading Model: 3D unet_xl
Found model class:  <function unet_xl at 0x7f7fdc422710>
MODALITIES 3
Transferring weights for finetuning
Checkpoint path: None
Loading from PyTorch Lightning checkpoint
INFO:root:Starting training with data from: /dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2
INFO:root:Starting training with data from: /dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2
INFO:root:Starting training with data from: /dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2
INFO:root:Starting training with data from: /dss/mcmlscratch/04/ra58seq2/finetuning/data/preprocessed/Task002_FOMO2
Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 362, in <module>
    main()
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 357, in main
    trainer.fit(model=model, datamodule=data_module, ckpt_path="last")
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 306, in advance
    batch, _, __ = next(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 113, in __getitem__
    return self._transform(data_dict, metadata)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 118, in _transform
    data_dict = self.composed_transforms(data_dict)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 17, in __call__
    augmented_np = clone_meningioma(trgt, **self.kwargs)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 186, in clone_meningioma
    src = shrink_src(src, trgt_brain_area)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 156, in shrink_src
    target_shape = get_shape_from_box(box)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 149, in get_shape_from_box
    box[3] - box[0],
TypeError: 'NoneType' object is not subscriptable

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|     | 1/2 [00:01<00:01,  0.95it/s]Sanity Checking DataLoader 0: 100%|| 2/2 [00:01<00:00,  1.16it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/100 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] Epoch 0:   0%|          | 0/100 [00:22<?, ?it/s]Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 362, in <module>
    main()
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 357, in main
    trainer.fit(model=model, datamodule=data_module, ckpt_path="last")
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 306, in advance
    batch, _, __ = next(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 113, in __getitem__
    return self._transform(data_dict, metadata)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 118, in _transform
    data_dict = self.composed_transforms(data_dict)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 17, in __call__
    augmented_np = clone_meningioma(trgt, **self.kwargs)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 186, in clone_meningioma
    src = shrink_src(src, trgt_brain_area)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 156, in shrink_src
    target_shape = get_shape_from_box(box)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 149, in get_shape_from_box
    box[3] - box[0],
TypeError: 'NoneType' object is not subscriptable

srun: error: mcml-hgx-a100-004: task 2: Exited with exit code 1
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|     | 1/2 [00:01<00:01,  0.93it/s]Sanity Checking DataLoader 0: 100%|| 2/2 [00:01<00:00,  1.72it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/100 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] Epoch 0:   0%|          | 0/100 [00:24<?, ?it/s]srun: error: mcml-hgx-a100-004: task 3: Exited with exit code 1
Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 362, in <module>
    main()
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 357, in main
    trainer.fit(model=model, datamodule=data_module, ckpt_path="last")
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 306, in advance
    batch, _, __ = next(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 113, in __getitem__
    return self._transform(data_dict, metadata)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 118, in _transform
    data_dict = self.composed_transforms(data_dict)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 17, in __call__
    augmented_np = clone_meningioma(trgt, **self.kwargs)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 186, in clone_meningioma
    src = shrink_src(src, trgt_brain_area)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 156, in shrink_src
    target_shape = get_shape_from_box(box)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 149, in get_shape_from_box
    box[3] - box[0],
TypeError: 'NoneType' object is not subscriptable

Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 362, in <module>
    main()
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 357, in main
    trainer.fit(model=model, datamodule=data_module, ckpt_path="last")
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 306, in advance
    batch, _, __ = next(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 113, in __getitem__
    return self._transform(data_dict, metadata)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 118, in _transform
    data_dict = self.composed_transforms(data_dict)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 17, in __call__
    augmented_np = clone_meningioma(trgt, **self.kwargs)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 186, in clone_meningioma
    src = shrink_src(src, trgt_brain_area)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 156, in shrink_src
    target_shape = get_shape_from_box(box)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 149, in get_shape_from_box
    box[3] - box[0],
TypeError: 'NoneType' object is not subscriptable

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|     | 1/2 [00:01<00:01,  0.98it/s]Sanity Checking DataLoader 0: 100%|| 2/2 [00:01<00:00,  1.80it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/100 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] [1;34mwandb[0m: 
[1;34mwandb[0m:  View run [33mfinetune_unet_xl_finetuning with larger artificial dataset_2_version_34[0m at: [34mhttps://wandb.ai/daniel-gloukhman-ludwig-maximilianuniversity-of-munich/fomo-finetuning/runs/8ctu1p47[0m
srun: error: mcml-hgx-a100-004: task 0: Exited with exit code 1
Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 362, in <module>
    main()
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/finetune.py", line 357, in main
    trainer.fit(model=model, datamodule=data_module, ckpt_path="last")
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 306, in advance
    batch, _, __ = next(data_fetcher)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 113, in __getitem__
    return self._transform(data_dict, metadata)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/yucca/modules/data/datasets/YuccaDataset.py", line 118, in _transform
    data_dict = self.composed_transforms(data_dict)
  File "/dss/dsshome1/04/ra58seq2/miniforge3/envs/codebase/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 17, in __call__
    augmented_np = clone_meningioma(trgt, **self.kwargs)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 186, in clone_meningioma
    src = shrink_src(src, trgt_brain_area)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 156, in shrink_src
    target_shape = get_shape_from_box(box)
  File "/dss/dsshome1/04/ra58seq2/lmu2025-miccai-fomo25/src/augmentations/clone_segmentation.py", line 149, in get_shape_from_box
    box[3] - box[0],
TypeError: 'NoneType' object is not subscriptable

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|     | 1/2 [00:00<00:00,  1.09it/s]Sanity Checking DataLoader 0: 100%|| 2/2 [00:01<00:00,  1.99it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/100 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] Epoch 0:   0%|          | 0/100 [00:29<?, ?it/s]srun: error: mcml-hgx-a100-004: task 1: Exited with exit code 1
